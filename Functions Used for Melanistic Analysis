#Functions ----
overlapCI <- function(animal1, animal2) {
  #data divided corresponding to each calculation as suggested by Ridout & Linkie, 2009
  if (min(length(animal1), length(animal2)) <= 75 & min(length(animal1), length(animal2)) > 15) {
    
    ovlEstimate <- overlapEst(animal1, animal2, adjust=c(0.8, NA, NA))[1]
    
    boot1 <- resample(animal1, numboot)
    boot2 <- resample(animal2, numboot)
    ovl.boot <- bootEst(boot1, boot2, adjust=c(0.8, NA, NA))[,1]
    ovl.boot.ci <- bootCI(ovlEstimate, ovl.boot)
    
    ovlEstimate<- round(ovlEstimate, digits = 4)
    ovlLower <- round(ovl.boot.ci[4,1], digits = 4)
    ovlUpper <- round(ovl.boot.ci[4,2], digits = 4)
    
    ovl <- (data.frame(
      "CI Estimate" = ovlEstimate,
      "CI Lower" = ovlLower,
      "CI Upper" = ovlUpper,
      row.names = NULL
    ))
  } else if (min(length(animal1), length(animal2)) > 75) {
    
    ovlEstimate <- overlapEst(animal1, animal2, adjust=c(NA, 1, NA))[2]
    
    boot1 <- resample(animal1, numboot)
    boot2 <- resample(animal2, numboot)
    
    ovl.boot <- bootEst(boot1, boot2, adjust=c(0.8, NA, NA))[,1]
    ovl.boot.ci <- bootCI(ovlEstimate, ovl.boot)
    
    ovlEstimate<- round(ovlEstimate, digits = 4)
    ovlLower <- round(ovl.boot.ci[4,1], digits = 4)
    ovlUpper <- round(ovl.boot.ci[4,2], digits = 4)
    
    ovl <<- (data.frame(
      "CI Estimate" = ovlEstimate,
      "CI Lower" = ovlLower,
      "CI Upper" = ovlUpper,
      row.names = NULL
    ))
    
  } else {    #Probably not used because eliminate any sample size that is less than or equal to 15
    ovlEstimate=NA
    ovlLower=NA
    ovlUpper=NA
    ovl <<- (data.frame(
      "CI Estimate" = ovlEstimate,
      "CI Lower" = ovlLower,
      "CI Upper" = ovlUpper,
      row.names = NULL
    ))
  }
  
  
  return(ovl)}
watson2 <- function(x, y) { #Function to calculate U-squared statistic, modified to work with "tied" data (See: Zar 1999)
  n1 <- length(x)
  n2 <- length(y)
  #if (min(n1, n2) <= 17) return("Sample too small")
  N <- n1+n2
  
  a <- c(x,y) #Putting all unique values into one ordered set, creating a unified coordinate system
  a <- a[duplicated(a) == FALSE]
  a <- a[order(a)]
  kmax <- length(a)
  
  t1 <- t2 <- m1 <- m2 <- c1 <- c2 <- rep.int(0, kmax) #Preallocating several variables
  
  for (k in 1:kmax) { #Finding the frequency of each value in x and y, respectively
    t1[k] <- sum(x==a[k])
    t2[k] <- sum(y==a[k])
  }
  
  m1 <- cumsum(t1) #Calculating the cumulative frequency distributions of x and y, respectively
  m2 <- cumsum(t2)
  
  c1 <- m1/n1 #Calculating the cumulative relative frequency distributions of x and y, respectively
  c2 <- m2/n2
  
  d <- c1-c2 
  t <- t1+t2 #The total frequency of each value; used when there are multiple observations of a value (ties)
  
  da <- sum(d*t)
  db <- sum(d*d*t)
  U2 <- ((n1*n2)/(N^2))*(db - ((da^2)/N)) #Calculating the U-squared statistic
  
  return(U2)
}
watson2test <- function(x, y) { #Function to approximate the p-value of Watson's U-squared, given two vectors (See: Tiku 1965)
  U2 <- watson2(x, y) #Calculate U-squared
  N <- length(x) + length(y)
  
  a <- ((21*N)-56)/(840*(N-1.5))
  b <- (N-1.5)/(42*N)
  f <- ((49*N)*(N-1))/(20*((N-1.5)^2)) #Approximation constants
  
  chi <- (U2-a)/b
  p <- pchisq(q = chi, df = f, lower.tail = FALSE) #Approximating from chi-squared distribution
  watson<-data.frame("Watson Stat" = round(U2, digits=4), "Watson P-value" = p)
  return(watson)
}
w.stat <- function(...) {
  
  #Function to calculate W statistic from 2 or more vectors of data (in RADIANS)
  
  
  
  #Data input and organization
  
  dataList <- list(...)
  
  unData <- data.frame(Point = sort(unlist(dataList)))
  
  n <- unlist(lapply(dataList, length)) #n is vector of sample sizes of each input vector
  
  N <- sum(n) #N is the *total* sample size, how many points were recorded overall
  
  r <- length(n) #r is the number of vectors input
  
  
  
  #Linear Rank
  
  unData["Rank"] <- 1:N
  
  for (i in 1:N) {
    
    whenSame <- unData$Point == unData$Point[i] #Create logical vector of which points of unData$Point are the same as a given point
    
    numSame <- sum(whenSame) #How many times does this value appear?
    
    
    
    if (numSame > 1) { #If a value appears more than once...
      
      unData$Rank[whenSame] <- rep(mean(unData$Rank[whenSame]), times = numSame) #...every point with that value should take the average Rank
      
    }
    
  }
  
  
  
  unData["Uniform"] <- 2 * pi * unData$Rank / N #Circular Rank, a.k.a: "Uniform Score"
  
  
  
  #Calculating W
  
  C <- S <- rep(0, times = length(n)) #Preallocate values
  
  for (i in 1:length(n)) {
    
    for (j in 1:n[i]) {
      
      rankOrder <- unData$Uniform[unData$Point == dataList[[i]][j]]
      
      rankOrder <- mean(rankOrder) #mean() condenses rankOrder to a single value if vector
      
      C[i] <- C[i] + cos(rankOrder)
      
      S[i] <- S[i] + sin(rankOrder)
      
    }
    
  }
  
  
  
  W <- 2 * sum((C^2 + S^2)/n)
  
  return(W)
  
}
w.prob <- function(..., trials = numboot, randomize = FALSE) {
  
  #Function to calculate p-value of the W statistic of given 2+ vectors of data (in RADIANS)
  
  
  
  #Data input 
  
  dataList <- list(...)
  
  W0 <- do.call(what = w.stat, args = dataList) #W statistic of actual data
  
  n <- unlist(lapply(dataList, length)) #n is vector of sample sizes of each input vector
  
  N <- sum(n) #N is the *total* sample size, how many points were recorded overall
  
  r <- length(n) #r is the number of vectors input
  
  
  
  if(randomize | min(n) < 10) {
    
    #Randomization test
    
    randW <- rep(x = NA, times = trials) #Preallocate result vector
    
    
    
    for (i in 1:trials) {
      
      randList <- list()
      
      randDat <- sample(x = unlist(dataList), size = N, replace = FALSE) #Randomly resample points for each data vector from total population without replacement
      
      for (j in 1:r) {
        
        if (j == 1) randList[[1]] <- randDat[1:n[j]] #The first "new" data vector has n[1] points
        
        else {
          
          nStart <- length(unlist(randList))
          
          randList[[j]] <- randDat[(nStart+1):(nStart+n[j])] #The j'th "new" data vector has n[j] points
          
        }
        
      }
      
      randW[i] <- do.call(what = w.stat, args = randList) #Once all "new" data vectors constructed, calculate W of "new" dataset and store it in the randW vector
      
    }
    
    sortW <- sort(randW) #Arrange W statistics from randomization in ascending order
    
    p <- which.min(abs(sortW-W0)) #Figure out where W0 fits into the randomized distribution
    
    return(data.frame("W Stat" = round(W0, digits=4), "W P-value" = 1-(p/trials))) #p-value = the fraction of trials that gave a W greater than W0
    
  }
  
  else {
    
    return(data.frame("W Stat" = round(W0, digits=4), "W P-value" = pchisq(q = W0, df = 2*r - 2, lower.tail = FALSE))) #Approximate with Chi-square
    
  }
  
}
binning <- function(x, bins = 12) {
  #x is a vector of times in radians
  #bins is the number of bins to put the data in
  
  cutoffs <- seq(from = 0, to = 2*pi, length.out = bins+1) #creates cutoffs for bins (time is in radians)
  n <- length(cutoffs)
  output <- rep(NA, times = length(x))   #puts all values to NA
  
  for (i in cutoffs[-n]) {
    output <- ifelse(
      test = x >= i,               #If x is greater than cutoff[n]...
      yes = which(i == cutoffs),   #Then output should be n
      no = output                  #Else it should stay what it is
    )
  }
  
  return(output)
}
chisquare <- function(animal1, animal2, bins=12) {
  animal1bin <- binning(animal1, bins)
  animal1bin <- setNames(tabulate(animal1bin), 1:max(animal1bin))
  animal2bin <- binning(animal2, bins)
  animal2bin <- setNames(tabulate(animal2bin), 1:max(animal2bin))
  animalbins <- rbind(animal1bin, animal2bin)
  size = 2 * bins
  
  chistat <- fisher.test(animalbins, simulate.p.value=TRUE, B=numboot) #may need B=1e7 (# replicaetes)
  
  pvalue = chistat["p.value"]
  
  pvalue <- unlist(pvalue, use.names = FALSE) #removes unwanted name of value so can assign, weird bug that didn't occur with other statistics
  
  return(pvalue)
}
overall<-function(animal1, animal2){
  n1<<-length(animal1)
  n2<<-length(animal2)
  
  
  CI<-overlapCI(animal1,animal2)#calculates coefficient of overlapping and confidence interval
  
  
  Watson2<-watson2test(animal1, animal2) 
  
  W<-w.prob(animal1,animal2)
  
  Chi2Pvalue<- chisquared(animal1,animal2)
  
  statistics <-
    data.frame(
      n1,
      n2,
      CI,
      Watson2,
      W,
      Chi2Pvalue
    )
  print("Done")
  return(statistics)
}
theme_mooring <- function() {
  theme_bw(base_size=40) %+replace%
    theme(
      panel.background = element_blank() 
      ,panel.border = element_blank()
      ,panel.grid = element_blank() 
      ,axis.line = element_line(color="black",linetype="solid", size=0.8) 
      ,complete = TRUE#since using complete bw theme
      ,axis.ticks.x = element_blank()
      ,axis.ticks.y = element_line(color="black",linetype="solid", size=0.8)
      ,axis.ticks.length=unit(-0.25, "cm")
      ,axis.title = element_text(face="plain") 
      ,axis.text.y=element_text(face="plain", size=40, color="black", margin = unit(c(0,0.5,0,1), unit="cm"))
      ,axis.text.x=element_text(face="plain", size=40, color="black", margin = unit(c(0.5,0,0,0), unit="cm"))
      ,legend.position="none"
    ) 
}
pvalueRAO <- function(U,n){
  if (n <= 30)
    table.row <- n - 3
  else if (n <= 32)
    table.row <- 27
  else if (n <= 37)
    table.row <- 28
  else if (n <= 42)
    table.row <- 29
  else if (n <= 47)
    table.row <- 30
  else if (n <= 62)
    table.row <- 31
  else if (n <= 87)
    table.row <- 32
  else if (n <= 125)
    table.row <- 33
  else if (n <= 175)
    table.row <- 34
  else if (n <= 250)
    table.row <- 35
  else if (n <= 350)
    table.row <- 36
  else if (n <= 450)
    table.row <- 37
  else if (n <= 550)
    table.row <- 38
  else if (n <= 650)
    table.row <- 39
  else if (n <= 750)
    table.row <- 40
  else if (n <= 850)
    table.row <- 41
  else if (n <= 950)
    table.row <- 42
  else table.row <- 43
  
  #designate p-value
  if (is.na(U))
    p <- "Sample Size too small"
  else if (U > rao.table[table.row, 1])
    p <- "P-value < 0.001"
  else if (U > rao.table[table.row, 2])
    p <- "0.001 < P-value < 0.01"
  else if (U > rao.table[table.row, 3])
    p <- "0.01 < P-value < 0.05"
  else if (U > rao.table[table.row, 4])
    p <- "0.05 < P-value < 0.10"
  else p <- "P-value > 0.10"
  
  return(p)
} #taken from circular Rao function to access p-value range
#overlapPlotCustom (overlapPlot function from overlap package (Ridout & Meredith, 2018)----
overlapPlotCustom <- function (A, B, xscale = 24, xcenter = c("noon", "midnight"), 
                               linetype = c(1, 2), linecol = c("black", "blue"), linewidth = c(1, 
                                                                                               1), olapcol = "lightgrey", rug = FALSE, extend = NULL, 
                               n.grid = 128, kmax = 3, adjust = 1, ...) 
{
  isMidnt <- match.arg(xcenter) == "midnight"
  bwA <- getBandWidth(A, kmax = kmax)/adjust
  bwB <- getBandWidth(B, kmax = kmax)/adjust
  if (is.na(bwA) || is.na(bwB)) 
    stop("Bandwidth estimation failed.")
  xsc <- if (is.na(xscale)) 
    1
  else xscale/(2 * pi)
  if (is.null(extend)) {
    xxRad <- seq(0, 2 * pi, length = n.grid)
  }
  else {
    xxRad <- seq(-pi/4, 9 * pi/4, length = n.grid)
  }
  if (isMidnt) 
    xxRad <- xxRad - pi
  xx <- xxRad * xsc
  densA <- densityFit(A, xxRad, bwA)/xsc
  densB <- densityFit(B, xxRad, bwB)/xsc
  densOL <- pmin(densA, densB)
  dots <- list(...)
  if (length(dots) == 1 && class(dots[[1]]) == "list") 
    dots <- dots[[1]]
  defaultArgs <- list(main = paste(deparse(substitute(A)), 
                                   "and", deparse(substitute(B))), xlab = "Time", ylab = "Density", 
                      bty = "o", type = "l", xlim = range(xx), ylim = c(0, 
                                                                        max(densA, densB)))
  useArgs <- modifyList(defaultArgs, dots)
  selPlot <- names(useArgs) %in% c(names(as.list(args(plot.default))), 
                                   names(par(no.readonly = TRUE)))
  plotArgs <- useArgs[selPlot]
  plotArgs$x <- 0
  plotArgs$y <- 0
  plotArgs$type <- "n"
  plotArgs$xaxt <- "n"
  
  do.call(plot, plotArgs, quote = TRUE)
  #rect(0,0,6,1, col=rgb(105/255, 167/255, 203/255,0.6),border=NA) #blue behind
  #rect(18,0,24,1, col=rgb(105/255, 167/255, 203/255,0.6),border=NA)
  polygon(c(max(xx), min(xx), xx), c(0, 0, densOL), border = NA, 
          col = olapcol)
  #rect(0,0,6,1, col=rgb(105/255, 167/255, 203/255,0.6),border=NA) #blue within plot
  #rect(18,0,24,1, col=rgb(105/255, 167/255, 203/255,0.6),border=NA)
  rect(-1,-1,6,1, col=rgb(105/255, 167/255, 203/255,0.6),border=NA) #blue beyond margin
  rect(18,-1,25,1, col=rgb(105/255, 167/255, 203/255,0.6),border=NA)
  if (!is.null(extend)) {
    if (isMidnt) {
      wrap <- c(-pi, pi) * xsc
    }
    else {
      wrap <- c(0, 2 * pi) * xsc
    }
    edge <- par("usr")
    rect(c(edge[1], wrap[2]), rep(edge[3], 2), c(wrap[1], 
                                                 edge[2]), rep(edge[4], 2), border = NA, col = extend)
    box(bty = useArgs$bty)
  }
  segments(xx[1], 0, xx[n.grid], 0, lwd = 0.5)
  lines(xx, densA, lty = linetype[1], col = linecol[1], lwd = linewidth[1])
  lines(xx, densB, lty = linetype[2], col = linecol[2], lwd = linewidth[2])
  if (rug) {
    if (isMidnt) {
      A <- ifelse(A < pi, A, A - 2 * pi)
      B <- ifelse(B < pi, B, B - 2 * pi)
    }
    axis(1, at = A * xsc, labels = FALSE, tcl = 0.35, lwd = 0, 
         lwd.ticks = 0.5, col = linecol[1])
    axis(1, at = B * xsc, labels = FALSE, tcl = -0.35, lwd = 0, 
         lwd.ticks = 0.5, pos = 0, col = linecol[2])
  }
  return(invisible(data.frame(x = xx, densityA = densA, densityB = densB)))
}
